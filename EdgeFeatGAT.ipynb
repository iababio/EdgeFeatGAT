{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "76z-j5go5OBz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c9506d-9ba1-497f-dcd9-9afe31be1f09"
      },
      "execution_count": 613,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 614,
      "metadata": {
        "id": "VLeCVWnok1Yb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear, Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GATConv, MessagePassing\n",
        "from torch_geometric.transforms import ToSparseTensor\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "from torch_geometric.datasets import TUDataset, Planetoid\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomGraphDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, mutag, protein):\n",
        "        self.mutag = TUDataset(root='/tmp/MUTAG', name='MUTAG') if mutag else None\n",
        "        self.protein = TUDataset(root='/tmp/PROTEINS', name='PROTEINS') if protein else None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mutag) if self.mutag is not None else len(self.protein)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mutag is not None:\n",
        "            return self.mutag[idx]\n",
        "        elif self.protein is not None:\n",
        "            return self.protein[idx]\n",
        "\n",
        "\n",
        "# To use the data loader, split the data into training and validation sets,\n",
        "# and create data loaders for the two datasets separately.\n",
        "\n",
        "dataset = CustomGraphDataset(mutag=True, protein=True)\n",
        "\n",
        "# Perform a train/test split\n",
        "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "ZorRoTMsk9O-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c23eb6-f3d8-47cc-8734-6e30dc18becf"
      },
      "execution_count": 615,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_loader:\n",
        "    print(batch.edge_attr.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9KoQMVMvFNH",
        "outputId": "7e6bb255-f648-4dfd-87bc-a12ba195b836"
      },
      "execution_count": 616,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1328, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EGConv(MessagePassing):\n",
        "    def __init__(self, node_feature_dim, edge_feature_dim, hidden_dim):\n",
        "        super(EGConv, self).__init__(aggr='add')\n",
        "\n",
        "        self.edge_transform = Linear(edge_feature_dim, hidden_dim)\n",
        "\n",
        "        # Add dropout in the edge_cnn layers\n",
        "        self.edge_cnn = nn.Sequential(\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5), # Add dropout layer\n",
        "            Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        # Add a dropout to the input features before the GAT layer\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        # Increase the number of heads in the GATConv. This increases model capacity\n",
        "        self.gat = GATConv(\n",
        "            in_channels=node_feature_dim,\n",
        "            out_channels=hidden_dim,\n",
        "            heads=8 # Increase number of heads\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr, batch):\n",
        "        edge_attr = self.edge_transform(edge_attr)\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "        x = self.dropout(x) # Apply dropout to input features\n",
        "        graph_features = self.gat(x, edge_index)\n",
        "\n",
        "        graph_features = global_mean_pool(graph_features, batch)\n",
        "\n",
        "        return graph_features"
      ],
      "metadata": {
        "id": "RidmKzBlvM0s"
      },
      "execution_count": 617,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_feature_dim = 7 # node features\n",
        "edge_feature_dim = 4 # edge features\n",
        "hidden_dim = 128\n",
        "model = EGConv(node_feature_dim, edge_feature_dim, hidden_dim)\n",
        "\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.70001 + 1e-4)\n",
        "\n",
        "# Create a DataLoader for your dataset\n",
        "# Create a DataLoader for your dataset\n",
        "dataset = CustomGraphDataset(mutag=True, protein=True)\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.01)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for data in loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Print or log the training loss at the end of each epoch\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n",
        "# Evaluation (you may need a separate validation dataset)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RocYHqWlbM2",
        "outputId": "f4449c7b-8ebd-45b3-acc5-633000a04df6"
      },
      "execution_count": 618,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.345521330833435\n",
            "Epoch 2, Loss: 0.8116307258605957\n",
            "Epoch 3, Loss: 0.7747025489807129\n",
            "Epoch 4, Loss: 0.5745782852172852\n",
            "Epoch 5, Loss: 0.4808226227760315\n",
            "Epoch 6, Loss: 0.7200015187263489\n",
            "Epoch 7, Loss: 0.65891033411026\n",
            "Epoch 8, Loss: 0.6042097210884094\n",
            "Epoch 9, Loss: 0.630759596824646\n",
            "Epoch 10, Loss: 0.5626121759414673\n",
            "Epoch 11, Loss: 0.47192808985710144\n",
            "Epoch 12, Loss: 0.4269729554653168\n",
            "Epoch 13, Loss: 0.5770348906517029\n",
            "Epoch 14, Loss: 0.46360188722610474\n",
            "Epoch 15, Loss: 0.5588556528091431\n",
            "Epoch 16, Loss: 0.5402517318725586\n",
            "Epoch 17, Loss: 0.4709661602973938\n",
            "Epoch 18, Loss: 0.5681589245796204\n",
            "Epoch 19, Loss: 0.5578107237815857\n",
            "Epoch 20, Loss: 0.6604284644126892\n",
            "Epoch 21, Loss: 0.5950865149497986\n",
            "Epoch 22, Loss: 0.5922209620475769\n",
            "Epoch 23, Loss: 0.4948349893093109\n",
            "Epoch 24, Loss: 0.5926079154014587\n",
            "Epoch 25, Loss: 0.5412247180938721\n",
            "Epoch 26, Loss: 0.556644856929779\n",
            "Epoch 27, Loss: 0.44538140296936035\n",
            "Epoch 28, Loss: 0.7246737480163574\n",
            "Epoch 29, Loss: 0.5707387328147888\n",
            "Epoch 30, Loss: 0.4292702376842499\n",
            "Epoch 31, Loss: 0.7274333834648132\n",
            "Epoch 32, Loss: 0.5348957777023315\n",
            "Epoch 33, Loss: 0.6176918745040894\n",
            "Epoch 34, Loss: 0.5568505525588989\n",
            "Epoch 35, Loss: 0.5638442039489746\n",
            "Epoch 36, Loss: 0.3980924189090729\n",
            "Epoch 37, Loss: 0.6298777461051941\n",
            "Epoch 38, Loss: 0.6132177710533142\n",
            "Epoch 39, Loss: 0.6462287902832031\n",
            "Epoch 40, Loss: 0.6669536232948303\n",
            "Epoch 41, Loss: 0.5361438989639282\n",
            "Epoch 42, Loss: 0.6096151471138\n",
            "Epoch 43, Loss: 0.5676509737968445\n",
            "Epoch 44, Loss: 0.5880540609359741\n",
            "Epoch 45, Loss: 0.6974970102310181\n",
            "Epoch 46, Loss: 0.5504926443099976\n",
            "Epoch 47, Loss: 0.7044745683670044\n",
            "Epoch 48, Loss: 0.6150978207588196\n",
            "Epoch 49, Loss: 0.5021585822105408\n",
            "Epoch 50, Loss: 0.5637286305427551\n",
            "Epoch 51, Loss: 0.5788231492042542\n",
            "Epoch 52, Loss: 0.5606942772865295\n",
            "Epoch 53, Loss: 0.5160683393478394\n",
            "Epoch 54, Loss: 0.5660402178764343\n",
            "Epoch 55, Loss: 0.48337259888648987\n",
            "Epoch 56, Loss: 0.47935041785240173\n",
            "Epoch 57, Loss: 0.5712191462516785\n",
            "Epoch 58, Loss: 0.576744019985199\n",
            "Epoch 59, Loss: 0.7785769701004028\n",
            "Epoch 60, Loss: 0.5331381559371948\n",
            "Epoch 61, Loss: 0.6027886271476746\n",
            "Epoch 62, Loss: 0.5531986355781555\n",
            "Epoch 63, Loss: 0.7120206952095032\n",
            "Epoch 64, Loss: 0.527213454246521\n",
            "Epoch 65, Loss: 0.6268293261528015\n",
            "Epoch 66, Loss: 0.6935449242591858\n",
            "Epoch 67, Loss: 0.6272721290588379\n",
            "Epoch 68, Loss: 0.5633053779602051\n",
            "Epoch 69, Loss: 0.48237499594688416\n",
            "Epoch 70, Loss: 0.6459149122238159\n",
            "Epoch 71, Loss: 0.6496410369873047\n",
            "Epoch 72, Loss: 0.4917941093444824\n",
            "Epoch 73, Loss: 0.5723921060562134\n",
            "Epoch 74, Loss: 0.59111487865448\n",
            "Epoch 75, Loss: 0.5949517488479614\n",
            "Epoch 76, Loss: 0.5268920660018921\n",
            "Epoch 77, Loss: 0.5879586935043335\n",
            "Epoch 78, Loss: 0.5766066908836365\n",
            "Epoch 79, Loss: 0.589381992816925\n",
            "Epoch 80, Loss: 0.5568165183067322\n",
            "Epoch 81, Loss: 0.4435155987739563\n",
            "Epoch 82, Loss: 0.5935216546058655\n",
            "Epoch 83, Loss: 0.6264209151268005\n",
            "Epoch 84, Loss: 0.6217180490493774\n",
            "Epoch 85, Loss: 0.6708669662475586\n",
            "Epoch 86, Loss: 0.5700098872184753\n",
            "Epoch 87, Loss: 0.6616610288619995\n",
            "Epoch 88, Loss: 0.5390772223472595\n",
            "Epoch 89, Loss: 0.5647282004356384\n",
            "Epoch 90, Loss: 0.6624778509140015\n",
            "Epoch 91, Loss: 0.5573931336402893\n",
            "Epoch 92, Loss: 0.6240053772926331\n",
            "Epoch 93, Loss: 0.7458520531654358\n",
            "Epoch 94, Loss: 0.5016689896583557\n",
            "Epoch 95, Loss: 0.5946405529975891\n",
            "Epoch 96, Loss: 0.6774758100509644\n",
            "Epoch 97, Loss: 0.6748291850090027\n",
            "Epoch 98, Loss: 0.4807843565940857\n",
            "Epoch 99, Loss: 0.6448861956596375\n",
            "Epoch 100, Loss: 0.6137623190879822\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EGConv()"
            ]
          },
          "metadata": {},
          "execution_count": 618
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a list to hold all predictions and true labels\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "for data in test_loader:\n",
        "    # Pass each batch through the model\n",
        "    out = model(data.x, data.edge_index, data.edge_attr, data.batch)\n",
        "\n",
        "    # Get the prediction\n",
        "    # Since your task is multi-class, choose the class with the highest output as the prediction\n",
        "    pred = out.argmax(dim=1)\n",
        "\n",
        "    # Save prediction and labels\n",
        "    all_preds.extend(pred.tolist())\n",
        "    all_labels.extend(data.y.tolist())\n",
        "\n",
        "# Convert to lists\n",
        "all_preds = [int(i) for i in all_preds]\n",
        "all_labels = [int(i) for i in all_labels]\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='weighted')  # set average='weighted' to calculate for multi-class/multi-label problems\n",
        "recall = recall_score(all_labels, all_preds, average='weighted')  # set average='weighted' to calculate for multi-class/multi-label problems\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted')  # set average='weighted' to calculate for multi-class/multi-label problems\n",
        "\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Precision: ', precision)\n",
        "print('Recall: ', recall)\n",
        "print('F1 Score: ', f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CpQMtvcbPxU",
        "outputId": "d8db486a-df59-4a0f-d82b-0bc3a517fa9e"
      },
      "execution_count": 619,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.7631578947368421\n",
            "Precision:  0.7844393592677346\n",
            "Recall:  0.7631578947368421\n",
            "F1 Score:  0.7690655209452202\n"
          ]
        }
      ]
    }
  ]
}