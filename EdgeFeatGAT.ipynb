{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "VLeCVWnok1Yb",
        "outputId": "849dabf7-9dab-4368-bdfe-01bf33894407"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-75b7a077e20b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGATConv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMessagePassing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mToSparseTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Linear, Parameter\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GATConv, MessagePassing\n",
        "from torch_geometric.transforms import ToSparseTensor\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "from torch_geometric.datasets import TUDataset, Planetoid\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomGraphDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, mutag, protein):\n",
        "        self.mutag = TUDataset(root='/tmp/MUTAG', name='MUTAG') if mutag else None\n",
        "        self.protein = Planetoid(root='/tmp/Protein', name='Protein') if protein else None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.mutag) if self.mutag is not None else len(self.protein)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mutag is not None:\n",
        "            return self.mutag[idx]\n",
        "        elif self.protein is not None:\n",
        "            return self.protein[idx]\n",
        "\n",
        "\n",
        "# To use the data loader, split the data into training and validation sets,\n",
        "# and create data loaders for the two datasets separately.\n",
        "\n",
        "dataset = CustomGraphDataset(mutag=True, protein=True)\n",
        "\n",
        "# Perform a train/test split\n",
        "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ],
      "metadata": {
        "id": "ZorRoTMsk9O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EGConv(MessagePassing):\n",
        "    def __init__(self, node_feature_dim, edge_feature_dim, hidden_dim, num_heads):\n",
        "        super(EGConv, self).__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n",
        "\n",
        "        # EdgeCNN for processing edge features\n",
        "        self.edge_cnn = nn.Sequential(\n",
        "            Linear(edge_feature_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            Linear(hidden_dim, hidden_dim)\n",
        "        )\n",
        "\n",
        "        # GAT layer for processing node and edge features\n",
        "        self.gat = GATConv(\n",
        "            in_channels=node_feature_dim + hidden_dim,\n",
        "            out_channels=hidden_dim,\n",
        "            heads=num_heads,\n",
        "            concat=True\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_attr):\n",
        "        # EdgeCNN processing is done dynamically in the message function.\n",
        "        # Apply GAT layer afterwards.\n",
        "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "        return self.gat(x, edge_index)\n",
        "\n",
        "    def message(self, x_j, edge_index_i, edge_attr):\n",
        "        # Apply EdgeCNN in the message function\n",
        "        edge_attr = self.edge_cnn(edge_attr)\n",
        "\n",
        "        # Concatenate edge and node features\n",
        "        x_j = torch.cat([x_j, edge_attr], dim=1)\n",
        "\n",
        "        return x_j"
      ],
      "metadata": {
        "id": "xkyp5BjflF6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "node_feature_dim = 64\n",
        "edge_feature_dim = 16\n",
        "hidden_dim = 128\n",
        "num_heads = 4\n",
        "model = EdgeGAT(node_feature_dim, edge_feature_dim, hidden_dim, num_heads)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Create a DataLoader for your dataset\n",
        "dataset = CustomGraphDataset()\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "PiCI7yjVlWnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for data in loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index, data.edge_attr)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print or log the training loss at the end of each epoch\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n",
        "# Evaluation (you may need a separate validation dataset)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "2RocYHqWlbM2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}